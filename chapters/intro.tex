\chapter{Introduction}
% Both of the works presented in this dissertation take advantage of two key ideas
% in order to effectively specialize for their respective domains.
% ...
% The first of these ideas is to simplify the synthesis task with system decomposition...
% The second key idea is leveraging system-specific metaprogramming abstractions...

% What is hard?
In recent years, the development of software systems has become increasingly
complex.
From the construction of large production key-value stores to Linux kernel JIT compilers,
% TODO should I include these examples?
%to the design of blockchain protocols and fault-tolerent networks,
modern systems must satisfy ever-increasing requirements on performance.
Additonally, the
correctness of these systems is now more important than ever. The
afformentioned storage systems are responsible for safely storing the data
of millions of people, while
the incorrect behavior of in-kernel compilers can subject the tens of millions of
Linux users to a slew of vulnerabilities.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Like software development for any domain, systems software development requires
three fundamental tasks:
\textbf{specifying} correct behavior at a high level,
\textbf{implementing} the system at a low level,
and \textbf{verifying} that the implementation correctly adheres to the specification.
Where systems software distinguishes itself is in the level of abstraction
at which the implementation operates.
Specifically, many systems must operate between layers of abstraction,
such as between source and target languages or between the application and
hardware layers of the operating system.
This means that manually implementing and verifying systems software requires
a high amount of effort from the developer, who must reason about the multiple abstraction
layers in addition to the execution of their implemented system.
Additionally, stringent requirements on performance for systems
further increase the difficulty of implementation and verification.

A well-studied technique for reducing the burden of both implementation
and verification from software designers is \textit{program synthesis}.
Program synthesis is an automated programming technique
that takes advantage of overlapping semantics between the three tasks described above
in order to automate software implementation and verification. 
To do so, synthesis tools take as input a specification and output both an implementation
as well as a certificate verifying that the implementation correctly behaves
according to the input specification.

The goal of my work is to automate system development with program synthesis.
Systems software is a particularly appealing target for program synthesis
due to the difficultly of manually implementing high-performance systems
that operate accross multiple abstraction layers.
However, for the same reasons that developers struggle to manually reason about systems,
creating tools to \textit{automatically} construct systems software poses
a uniquely difficult challenge.
Synthesis tools for systems must not only consider the space of candidate implementations,
but also the complex semantics of the abstractions that the system implementation operates between.
For JIT compiler synthesis tools, this means considering all possible executions of both source and target programs;
for crash consistency automation, this means reasoning about sets of disk writes
that a given storage system may issue,
as well as any possible reorderings of those writes made by the disk hardware.
Moreover, demands on the performance of systems further complicate this task,
restricting the space of acceptable outputs from a systems synthesis tool.

To overcome these unique challenges, this dissertation presents a variety of novel
\textit{system decomposition} and \textit{metaprogramming abstraction} techniques.
%In this work, I identify two key observations that enable the creation of synthesis tools
\textbf{Program decomposition} allows synthesis tools to generate smaller target programs.
By considering systems as a conjunction of smaller pieces,
synthesis tools can search for candidate programs that implement a single piece.
The resulting synthesized program can be combined with either user-written code or
other synthesized system pieces, effectively reducing the developer burden.
% JitSynth: break up into minicompilers (TODO)
% DepSynth: consider storage mechanism separately from crash consistency mechanism (TODO)
Second, system-specific \textbf{metaprogram abstractions} enable synthesis tools to reason 
about candidate programs that themselves take DSL programs as input.
By reasoning about these simpler abstractions rather than the complex systems directly,
synthesis tools are able to more efficiently search over candidate programs.
% JitSynth: design metasketch to describe common minicompiler patterns (TODO)
% DepSynth: design rules language to describe any runtime dependencies (TODO)
In the next two sections, I describe how these observations enabled the creation of
synthesis tools for both in-kernel JIT compliers and for crash consistent storage systems.

My thesis is that \textit{program
synthesis is an effective tool for designing systems that are both correct and
performant}.  This dissertation explores this thesis over two particular types
of systems --- just-in-time compilers and crash consistent storage systems ---
and demonstrates how new synthesis tools can reduce implementation and verification
effort for developers despite the size and complexity of these systems.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if 0
% Why is it hard?
Modern systems developers must tackle three challenges when constructing
systems that both meet high performance criteria and exhibit correct behavior.
First, developers must \textbf{specify} the intended behavior of their system at a high
level. This specification can be encoded in a variety of ways, from
English-text design documents to formal logic specifications.
Second, developers must \textbf{implement} their system in accordance with the defined
specificaiton. Generally, this implementation done at a lower level than the
specification and may contain details or optimizations not referenced by the specification.
Third, developers must \textbf{verify} that their implementation behaves correctly 
according to their specification. Much like the last two tasks, verification can be done
in one of several ways, from testing to manual or automated proofs to code review.
However, no matter the method for each of these three tasks,
all pose a significant burden of effort to systems developers.

% In order to ameliorate the burden \todo{continue} Various areas of work have
% aimed to limit the burdens , 

% How can we make it easier?
Between these three efforts, system developers repeat encoding the semantics of
their system: the implementation of the system must adhere to the semantics
given by the specification, and manual verification efforts like testing again
repeat these semantics for specific inputs to the system.
The goal of my work is to take advantage of the overlap between these three tasks
and reduce the burden on systems developers with \textit{program synthesis}.
Program synthesis is an automated programming technique
that takes as input a specification and outpus both an implementation
as well as some certificate verifying that the implementation correctly behaves
according to the input specification.
This work presents new techniques that enable the construction of program
synthesis tools for systems software, and additionally demonstrates the
efficacy of these tools.

%In the context of 
%By doing so, synthesis eliminates the
%effort from developers to both implement and verify their systems, requiring
%only a specification for the system.

% What will I say to demonstrate the "how"? 
%In this work, I aim to
%demonstrate the benefits of using program synthesis tools in order to both
%design and implement systems software.

%This work presents new techniques that enable the construction of program
%synthesis tools for systems software, and additionally demonstrates the
%efficacy of these tools.
My thesis is that \textit{program
synthesis is an effective tool for designing systems that are both correct and
performant}.  This dissertation explores this thesis over two particular types
of systems --- just-in-time compilers and crash consistent storage systems ---
and demonstrates how new synthesis tools can reduce implementation and verification
effort for developers despite the size and complexity of these systems.


\section{Challenges}

The main challenge in building any synthesis tool comes from the size of the
search space of possible implementations.
In order to generate verifiably correct implementations, synthesis tools both limit
their search space and order their search to prioritize the most likely candidates.
One common technique synthesis tools use to both limit and order the search space is
to specialize over a particular domain.
For example, a large body of work focuses solely on synthesizing classes of spreadsheet
table transformations \todo{cite}.
These tools restrict their space to sequential programs that invoke a set
of operations over relevant to these particular transformations, and also intelligently
order their search to prioritize candidates that are most likely desired by the synthesis
tool user.
% By doing so, % TODO finish this?
Another common technique for ordering the space of candidate output programs is to
consider the size of candidates.
Since the number of candidate programs increases exponentially with size,
synthesis tools often prioritize searching for smaller programs before larger ones
(EXAMPLES\todo{Cite examples} for example).
In general, synthesizing large complex programs is much more difficult than
synthesizing small blocks of code.


Unline most existing target domains for program synthesis, systems software reasons
about multiple layers of abstraction.
Specifically, many systems consider domain-specific language (DSL) programs as input,
so synthesis tools for systems must reason about the execution of both input DSL programs
and the system implementation itself.
%these large systems often encode highly complex semantics
%which often reason at multiple levels of abstraction.
Additionally, systems software
often requires a monolithic amount of code, on the order of tens of thousands
of lines \todo{cite examples of big systems}.
%manually generated proofs of correctness for these systems can be just as large if not
%moreso. \todo{cite big proofs of verified OS?}
This means that na\"ively applying existing techniques for program synthesis to generate
systems software is infeasible.

In this work, I identify two key observations that enable the creation of synthesis tools
that effectively generate correct and performant systems software.
First, \textbf{program decomposition} allows synthesis tools to generate smaller target programs.
By considering systems as a conjunction of smaller pieces,
synthesis tools can search for candidate programs that implement a single piece.
The resulting synthesized program can be combined with either user-written code or
other synthesized system pieces, effectively reducing the developer burden.
% JitSynth: break up into minicompilers (TODO)
% DepSynth: consider storage mechanism separately from crash consistency mechanism (TODO)
Second, system-specific \textbf{metaprogram abstractions} enable synthesis tools to reason 
about candidate programs that themselves take DSL programs as input.
By reasoning about these simpler abstractions rather than the complex systems directly,
synthesis tools are able to more efficiently search over candidate programs.
% JitSynth: design metasketch to describe common minicompiler patterns (TODO)
% DepSynth: design rules language to describe any runtime dependencies (TODO)
In the next two sections, I describe how these observations enabled the creation of
synthesis tools for both in-kernel JIT compliers and for crash consistent storage systems.

\fi

%%%%%%%%%% %%%%%%%%%% %%%%%%%%%% %%%%%%%%%% %%%%%%%%%% %%%%%%%%%% %%%%%%%%%% %%%%%%%%%%

\section{Synthesis for In-Kernel JIT Compilers}
Modern operating systems have become increasingly extensible and customizable.
One way these systems enable customization is by
allowing users to submit custom code for kernel execution
written in an \textit{in-kernel DSL}.
Initially designed for network packet filtering, 
in-kernel DSLs like eBPF \todo{cite} enable kernel extentions
such as performance monitoring, load balancing, and intrusion detection.\todo{cite https://ebpf.io/case-studies/}
For performance reasons, operating systems use just-in-time (JIT) compilers
to execute in-kernel DSL programs.
However,
% as mentioned previously, % TODO?
these JIT compilers can be the source of major kernel bugs.\todo{cite}
Moreover, writing JIT compilers can pose a substantial effort to developers,
requiring on the order of thousands of lines of code.\todo{cite}

In \cref{c:jitsynth}, I present \jitsynth, a program synthesis tool that
automatically generates JIT compilers for in-kernel DSLs
given a specification of the source and target language.
Existing work has demonstrated how the correctness of JIT compilers
can be proven manually\todo{cite},
but the effort of such proofs is highly non-trivial.
By synthesizing JIT compilers, developers both avoid the burden of implementing
such systems \textit{and} can guarantee correctness
without requiring intensive proofs.

% JitSynth: break up into minicompilers (TODO)
In order to synthesize such massive and complex systems,
\jitsynth considers the synthesis problem as one over per-instruction compilers
between \textit{abstract register machines} --- an abstraction over
in-kernel DSLs and other low-level languages introduced in \cref{c:jitsynth}.
\jitsynth decomposes the synthesis problem for per-instruction compilers
into multiple synthesis tasks for \textit{minicompilers}
that translate only one source instruction. % TODO include this line?
% JitSynth: design metasketch to describe common minicompiler patterns (TODO)
To prune and prioritize the search space for minicompilers,
\jitsynth takes advantage of a novel \textit{compiler metasketch}
that enables the efficient exploration of candidate minicompilers
using off-the-shelf satisfiability solvers.
With \jitsynth, we have synthesized three JIT compilers:
one from eBPF to RISC-V,
one from classic BPF to eBPF,
and one from libseccomp to eBPF.
Moreover, we have confirmed that the synthesized eBPF to RISC-V compiler
lacks bugs previously found in the existing Linux compiler.

\section{Automatic Crash Consistency with Synthesis}
Storage systems face an increasing demand for reliability.
From Linux file systems to large cloud-based key-value stores,
storage systems must maintain the integrity of their data
even in the presence of system crashes.
This property of storage systems is known as \textit{crash consistency}.
Guaranteeing crash consistency is a highly non-trivial task for developers,
as it requires maintaining complex invariants that depend greatly on
storage system implementation details.
Moreover, failing to guarantee crash consistency may result in severe impacts,
including costly slowdowns and massive data losses. % TODO make more concrete
% TODO finish: Highlight what can go wrong if crash consistency is done incorrectly
% TODO
% DepSynth: consider storage mechanism separately from crash consistency mechanism (TODO)
% DepSynth: design rules language to describe any runtime dependencies (TODO)

\cref{c:depsynth} presents \depsynth, a tool for automatically generating crash consistency
code for storage systems.
\depsynth takes advantage of the observation
(identified in previous work \todo{cite Featherstitch})
that crash consistency mechanisms fundamentally enforce \textit{write-before relationships}.
To automate crash consistency,
\depsynth takes as input the implementation of a (non-crash consistent) storage system together
with a set of example programs over the system called \textit{litmus tests}.
The output is a set of \textit{dependency rules} which specify, at runtime,
the required write-before relationships to enforce.

% TODO revise this paragraph
We take advantage of several novel abstractions in order enable
automatic crash consistency with \depsynth.
First, we assume a new \textit{angelic crash consistency} model
that delegates enforcement of write-before relationships to a
\textit{dependency-aware buffer cache},
which sits between the storage system software and disk hardware layers.
Second, we introduce a language for dependency rules
that allows for both \textit{expressive} and \textit{generalizable} rules.
Finally, we describe a new search for dependency rules
directed by input litmus tests.
These insights enable \depsynth to synthesize dependency rules for an existing
production key-value store at Amazon\todo{cite shardstore} in 49\todo{macro this} minutes.

\section{Contributions}
The remainder of this dissertation is broken into two chapters.
\cref{c:jitsynth} introduces \jitsynth and the techniques that enable
\jitsynth to synthesize in-kernel JIT compilers.
By decomposing the search with minicompilers
and efficiently exploring the space with novel metasketches,
\jitsynth is able to synthesize correct JITs that perform
comparably to their hand-written counterparts.

\cref{c:depsynth} presents \depsynth, a tool for automating
crash consistency in storage systems. In \cref{c:depsynth},
we introduce a new dependency rule language that describes rules
which specify required write-before relationships for a storage system
at runtime. This abstraction over write-before relationships, along
with a new per-litmus-test search, allows \depsynth to synthesize
correct dependency rules for a production system.
Moreover, these generated rules have nearly the same effect on performance
as dependencies hand-written by experts.

Both of these chapters demonstrate
how program synthesis can aid developers in building
correct and performant systems.

